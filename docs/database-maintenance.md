# ë°ì´í„°ë² ì´ìŠ¤ ìœ ì§€ë³´ìˆ˜ ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” Supabase ë¬´ë£Œ í‹°ì–´(500MB)ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ë°ì´í„°ë² ì´ìŠ¤ ìœ ì§€ë³´ìˆ˜ ì „ëµì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ëª©ì°¨

1. [ìš©ëŸ‰ ê´€ë¦¬ ì „ëµ](#ìš©ëŸ‰-ê´€ë¦¬-ì „ëµ)
2. [ì•„ì¹´ì´ë¹™](#ì•„ì¹´ì´ë¹™)
3. [ì ì§„ì  ì‚­ì œ](#ì ì§„ì -ì‚­ì œ)
4. [ìš©ëŸ‰ ì•Œë¦¼ ì„¤ì •](#ìš©ëŸ‰-ì•Œë¦¼-ì„¤ì •)
5. [ìë™í™” êµ¬í˜„](#ìë™í™”-êµ¬í˜„)

## ìš©ëŸ‰ ê´€ë¦¬ ì „ëµ

### ë°ì´í„° ë³´ê´€ ì •ì±…

| ì¼ì¼ í¬ë¡¤ë§ ìˆ˜ | ê¶Œì¥ ë³´ê´€ ê¸°ê°„ | ì •ë¦¬ ì£¼ê¸° |
| -------------- | -------------- | --------- |
| 50ê°œ ì´í•˜      | 1ë…„            | 1ë…„ë§ˆë‹¤   |
| 50-100ê°œ       | 6ê°œì›”          | 6ê°œì›”ë§ˆë‹¤ |
| 100-200ê°œ      | 3-6ê°œì›”        | 3ê°œì›”ë§ˆë‹¤ |
| 200ê°œ ì´ìƒ     | 3ê°œì›”          | ë§¤ì›”      |

### í˜„ì¬ ìš©ëŸ‰ í™•ì¸

```sql
-- í…Œì´ë¸” í¬ê¸° í™•ì¸
SELECT
  pg_size_pretty(pg_total_relation_size('posts')) as total_size,
  pg_size_pretty(pg_relation_size('posts')) as table_size,
  pg_size_pretty(pg_indexes_size('posts')) as indexes_size;

-- í¬ìŠ¤íŠ¸ ìˆ˜ í™•ì¸
SELECT COUNT(*) as total_posts FROM posts;

-- ì›”ë³„ í¬ìŠ¤íŠ¸ ìˆ˜ í†µê³„
SELECT
  DATE_TRUNC('month', created_at) as month,
  COUNT(*) as posts_count,
  pg_size_pretty(SUM(octet_length(title) + octet_length(COALESCE(summary, '')) + octet_length(original_link))) as estimated_size
FROM posts
GROUP BY month
ORDER BY month DESC;
```

## ì•„ì¹´ì´ë¹™

### 1. ìˆ˜ë™ ì•„ì¹´ì´ë¹™

#### ì „ì²´ ë°ì´í„° ë°±ì—…

```bash
# Supabase CLI ì‚¬ìš©
supabase db dump -f backup_$(date +%Y%m%d).sql

# ë˜ëŠ” íŠ¹ì • í…Œì´ë¸”ë§Œ
supabase db dump -f posts_backup_$(date +%Y%m%d).sql --table posts
```

#### CSVë¡œ ë‚´ë³´ë‚´ê¸°

```sql
-- Supabase SQL Editorì—ì„œ ì‹¤í–‰
COPY (
  SELECT
    id,
    title,
    summary,
    original_link,
    category,
    created_at,
    updated_at
  FROM posts
  WHERE created_at < NOW() - INTERVAL '6 months'
  ORDER BY created_at DESC
) TO '/tmp/posts_archive.csv' WITH CSV HEADER;
```

ë˜ëŠ” Supabase Dashboardì—ì„œ:

1. **Database** â†’ **Tables** â†’ `posts`
2. í•„í„° ì ìš© (ì˜ˆ: created_at < 6 months ago)
3. **Export** â†’ **CSV**

### 2. ìë™ ì•„ì¹´ì´ë¹™ ìŠ¤í¬ë¦½íŠ¸

`scripts/archive_old_posts.py`:

```python
#!/usr/bin/env python3
"""
ì˜¤ë˜ëœ í¬ìŠ¤íŠ¸ë¥¼ CSVë¡œ ì•„ì¹´ì´ë¹™í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import os
import csv
from datetime import datetime, timedelta
from supabase import create_client

# ì„¤ì •
ARCHIVE_MONTHS = 6  # 6ê°œì›” ì´ìƒ ëœ ë°ì´í„° ì•„ì¹´ì´ë¹™
ARCHIVE_DIR = "archives"

# Supabase í´ë¼ì´ì–¸íŠ¸
supabase = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_KEY")
)

def archive_old_posts():
    """ì˜¤ë˜ëœ í¬ìŠ¤íŠ¸ë¥¼ CSVë¡œ ì €ì¥"""

    # ì•„ì¹´ì´ë¸Œ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(ARCHIVE_DIR, exist_ok=True)

    # ì•„ì¹´ì´ë¹™ ê¸°ì¤€ ë‚ ì§œ
    cutoff_date = (datetime.now() - timedelta(days=ARCHIVE_MONTHS * 30)).isoformat()

    # ì˜¤ë˜ëœ í¬ìŠ¤íŠ¸ ì¡°íšŒ
    result = supabase.table('posts')\
        .select('*')\
        .lt('created_at', cutoff_date)\
        .order('created_at', desc=True)\
        .execute()

    posts = result.data

    if not posts:
        print("ğŸ“­ ì•„ì¹´ì´ë¹™í•  í¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    # CSV íŒŒì¼ëª…
    filename = f"{ARCHIVE_DIR}/posts_archive_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"

    # CSVë¡œ ì €ì¥
    with open(filename, 'w', newline='', encoding='utf-8') as f:
        if posts:
            writer = csv.DictWriter(f, fieldnames=posts[0].keys())
            writer.writeheader()
            writer.writerows(posts)

    print(f"âœ… {len(posts)}ê°œ í¬ìŠ¤íŠ¸ë¥¼ ì•„ì¹´ì´ë¹™í–ˆìŠµë‹ˆë‹¤: {filename}")
    print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(filename) / 1024:.2f} KB")

    return len(posts)

if __name__ == "__main__":
    count = archive_old_posts()
    print(f"\nğŸ‰ ì•„ì¹´ì´ë¹™ ì™„ë£Œ: {count}ê°œ í¬ìŠ¤íŠ¸")
```

### 3. ì•„ì¹´ì´ë¸Œ ë³µì›

```python
#!/usr/bin/env python3
"""
ì•„ì¹´ì´ë¸Œëœ ë°ì´í„°ë¥¼ ë³µì›í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import csv
from supabase import create_client
import os

def restore_from_archive(csv_file):
    """CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë³µì›"""

    supabase = create_client(
        os.getenv("SUPABASE_URL"),
        os.getenv("SUPABASE_KEY")
    )

    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        posts = list(reader)

    # ë°°ì¹˜ë¡œ ì‚½ì… (1000ê°œì”©)
    batch_size = 1000
    for i in range(0, len(posts), batch_size):
        batch = posts[i:i + batch_size]
        supabase.table('posts').upsert(batch).execute()
        print(f"âœ… {i + len(batch)}/{len(posts)} ë³µì› ì™„ë£Œ")

    print(f"ğŸ‰ ì´ {len(posts)}ê°œ í¬ìŠ¤íŠ¸ ë³µì› ì™„ë£Œ")

if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python restore_archive.py <csv_file>")
        sys.exit(1)

    restore_from_archive(sys.argv[1])
```

## ì ì§„ì  ì‚­ì œ

### 1. ë°°ì¹˜ ì‚­ì œ í•¨ìˆ˜

```sql
-- Supabase SQL Editorì—ì„œ ì‹¤í–‰
CREATE OR REPLACE FUNCTION delete_old_posts_batch(
  months_old INTEGER DEFAULT 6,
  batch_size INTEGER DEFAULT 1000
)
RETURNS TABLE(deleted_count INTEGER) AS $$
DECLARE
  total_deleted INTEGER := 0;
  rows_deleted INTEGER;
BEGIN
  LOOP
    -- ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì‚­ì œ
    DELETE FROM posts
    WHERE id IN (
      SELECT id FROM posts
      WHERE created_at < NOW() - (months_old || ' months')::INTERVAL
      LIMIT batch_size
    );

    GET DIAGNOSTICS rows_deleted = ROW_COUNT;
    total_deleted := total_deleted + rows_deleted;

    -- ë” ì´ìƒ ì‚­ì œí•  í–‰ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
    EXIT WHEN rows_deleted = 0;

    -- ì ì‹œ ëŒ€ê¸° (ë°ì´í„°ë² ì´ìŠ¤ ë¶€í•˜ ê°ì†Œ)
    PERFORM pg_sleep(0.1);
  END LOOP;

  RETURN QUERY SELECT total_deleted;
END;
$$ LANGUAGE plpgsql;
```

### 2. ì‚¬ìš© ë°©ë²•

```sql
-- 6ê°œì›” ì´ìƒ ëœ í¬ìŠ¤íŠ¸ë¥¼ 1000ê°œì”© ì‚­ì œ
SELECT delete_old_posts_batch(6, 1000);

-- 3ê°œì›” ì´ìƒ ëœ í¬ìŠ¤íŠ¸ë¥¼ 500ê°œì”© ì‚­ì œ
SELECT delete_old_posts_batch(3, 500);
```

### 3. Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ì ì§„ì  ì‚­ì œ

`scripts/cleanup_old_posts.py`:

```python
#!/usr/bin/env python3
"""
ì˜¤ë˜ëœ í¬ìŠ¤íŠ¸ë¥¼ ì ì§„ì ìœ¼ë¡œ ì‚­ì œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import os
import time
from datetime import datetime, timedelta
from supabase import create_client

# ì„¤ì •
CLEANUP_MONTHS = 6  # 6ê°œì›” ì´ìƒ ëœ ë°ì´í„° ì‚­ì œ
BATCH_SIZE = 1000   # í•œ ë²ˆì— ì‚­ì œí•  ê°œìˆ˜
SLEEP_SECONDS = 1   # ë°°ì¹˜ ê°„ ëŒ€ê¸° ì‹œê°„

# Supabase í´ë¼ì´ì–¸íŠ¸
supabase = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_KEY")
)

def cleanup_old_posts():
    """ì˜¤ë˜ëœ í¬ìŠ¤íŠ¸ë¥¼ ì ì§„ì ìœ¼ë¡œ ì‚­ì œ"""

    cutoff_date = (datetime.now() - timedelta(days=CLEANUP_MONTHS * 30)).isoformat()
    total_deleted = 0

    print(f"ğŸ—‘ï¸  {CLEANUP_MONTHS}ê°œì›” ì´ìƒ ëœ í¬ìŠ¤íŠ¸ ì‚­ì œ ì‹œì‘...")
    print(f"ğŸ“… ê¸°ì¤€ ë‚ ì§œ: {cutoff_date}")

    while True:
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì¡°íšŒ
        result = supabase.table('posts')\
            .select('id')\
            .lt('created_at', cutoff_date)\
            .limit(BATCH_SIZE)\
            .execute()

        posts = result.data

        if not posts:
            break

        # ë°°ì¹˜ ì‚­ì œ
        ids = [post['id'] for post in posts]
        supabase.table('posts').delete().in_('id', ids).execute()

        total_deleted += len(posts)
        print(f"âœ… {total_deleted}ê°œ ì‚­ì œ ì™„ë£Œ...")

        # ëŒ€ê¸°
        if len(posts) == BATCH_SIZE:
            time.sleep(SLEEP_SECONDS)
        else:
            break

    print(f"\nğŸ‰ ì •ë¦¬ ì™„ë£Œ: ì´ {total_deleted}ê°œ í¬ìŠ¤íŠ¸ ì‚­ì œ")
    return total_deleted

if __name__ == "__main__":
    cleanup_old_posts()
```

## ìš©ëŸ‰ ì•Œë¦¼ ì„¤ì •

### 1. ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í•¨ìˆ˜

```sql
-- ë°ì´í„°ë² ì´ìŠ¤ ìš©ëŸ‰ í™•ì¸ í•¨ìˆ˜
CREATE OR REPLACE FUNCTION check_database_size()
RETURNS TABLE(
  total_size_mb NUMERIC,
  posts_size_mb NUMERIC,
  usage_percent NUMERIC,
  alert_level TEXT
) AS $$
DECLARE
  max_size_mb CONSTANT NUMERIC := 500;  -- ë¬´ë£Œ í‹°ì–´ ì œí•œ
  total_bytes BIGINT;
  posts_bytes BIGINT;
BEGIN
  -- ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸°
  SELECT pg_database_size(current_database()) INTO total_bytes;

  -- posts í…Œì´ë¸” í¬ê¸°
  SELECT pg_total_relation_size('posts') INTO posts_bytes;

  RETURN QUERY
  SELECT
    ROUND(total_bytes / 1024.0 / 1024.0, 2) as total_size_mb,
    ROUND(posts_bytes / 1024.0 / 1024.0, 2) as posts_size_mb,
    ROUND((total_bytes / 1024.0 / 1024.0 / max_size_mb) * 100, 2) as usage_percent,
    CASE
      WHEN (total_bytes / 1024.0 / 1024.0) >= max_size_mb * 0.9 THEN 'ğŸ”´ CRITICAL'
      WHEN (total_bytes / 1024.0 / 1024.0) >= max_size_mb * 0.8 THEN 'ğŸŸ  WARNING'
      WHEN (total_bytes / 1024.0 / 1024.0) >= max_size_mb * 0.6 THEN 'ğŸŸ¡ CAUTION'
      ELSE 'ğŸŸ¢ OK'
    END as alert_level;
END;
$$ LANGUAGE plpgsql;
```

### 2. ìš©ëŸ‰ ì²´í¬ ìŠ¤í¬ë¦½íŠ¸

`scripts/check_db_capacity.py`:

```python
#!/usr/bin/env python3
"""
ë°ì´í„°ë² ì´ìŠ¤ ìš©ëŸ‰ì„ í™•ì¸í•˜ê³  ì•Œë¦¼ì„ ë³´ë‚´ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import os
from supabase import create_client

# ì„¤ì •
WARNING_THRESHOLD = 80  # 80% ì´ìƒì´ë©´ ê²½ê³ 
CRITICAL_THRESHOLD = 90  # 90% ì´ìƒì´ë©´ ìœ„í—˜

# Supabase í´ë¼ì´ì–¸íŠ¸
supabase = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_KEY")
)

def check_capacity():
    """ë°ì´í„°ë² ì´ìŠ¤ ìš©ëŸ‰ í™•ì¸"""

    # SQL í•¨ìˆ˜ í˜¸ì¶œ
    result = supabase.rpc('check_database_size').execute()

    if not result.data:
        print("âŒ ìš©ëŸ‰ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    data = result.data[0]

    print("\n" + "="*50)
    print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ìš©ëŸ‰ ë¦¬í¬íŠ¸")
    print("="*50)
    print(f"ì „ì²´ í¬ê¸°: {data['total_size_mb']} MB")
    print(f"Posts í…Œì´ë¸”: {data['posts_size_mb']} MB")
    print(f"ì‚¬ìš©ë¥ : {data['usage_percent']}%")
    print(f"ìƒíƒœ: {data['alert_level']}")
    print("="*50 + "\n")

    # ì•Œë¦¼ ë ˆë²¨ì— ë”°ë¥¸ ì•¡ì…˜
    usage = float(data['usage_percent'])

    if usage >= CRITICAL_THRESHOLD:
        print("ğŸ”´ ìœ„í—˜: ì¦‰ì‹œ ë°ì´í„° ì •ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
        print("   ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("   python scripts/archive_old_posts.py")
        print("   python scripts/cleanup_old_posts.py")
        return "CRITICAL"

    elif usage >= WARNING_THRESHOLD:
        print("ğŸŸ  ê²½ê³ : ê³§ ë°ì´í„° ì •ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        print("   1-2ì£¼ ë‚´ì— ì •ë¦¬ë¥¼ ê³„íší•˜ì„¸ìš”.")
        return "WARNING"

    elif usage >= 60:
        print("ğŸŸ¡ ì£¼ì˜: ìš©ëŸ‰ì„ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”.")
        return "CAUTION"

    else:
        print("ğŸŸ¢ ì •ìƒ: ìš©ëŸ‰ì´ ì¶©ë¶„í•©ë‹ˆë‹¤.")
        return "OK"

if __name__ == "__main__":
    status = check_capacity()

    # í¬ìŠ¤íŠ¸ í†µê³„
    result = supabase.table('posts').select('id', count='exact').execute()
    print(f"ğŸ“ ì´ í¬ìŠ¤íŠ¸ ìˆ˜: {result.count}ê°œ\n")
```

### 3. GitHub Actionsë¡œ ìë™ ì•Œë¦¼

`.github/workflows/db_capacity_check.yml`:

```yaml
name: Database Capacity Check

on:
  schedule:
    - cron: "0 0 * * 0" # ë§¤ì£¼ ì¼ìš”ì¼ ìì •
  workflow_dispatch: # ìˆ˜ë™ ì‹¤í–‰

jobs:
  check-capacity:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install supabase

      - name: Check database capacity
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python scripts/check_db_capacity.py

      - name: Create Issue if Critical
        if: failure()
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ğŸ”´ ë°ì´í„°ë² ì´ìŠ¤ ìš©ëŸ‰ ìœ„í—˜',
              body: 'ë°ì´í„°ë² ì´ìŠ¤ ìš©ëŸ‰ì´ ìœ„í—˜ ìˆ˜ì¤€ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì •ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.',
              labels: ['database', 'urgent']
            })
```

## ìë™í™” êµ¬í˜„

### í†µí•© ìœ ì§€ë³´ìˆ˜ ì›Œí¬í”Œë¡œìš°

`.github/workflows/db_maintenance.yml`:

```yaml
name: Database Maintenance

on:
  schedule:
    - cron: "0 2 1 * *" # ë§¤ì›” 1ì¼ ì˜¤ì „ 2ì‹œ
  workflow_dispatch: # ìˆ˜ë™ ì‹¤í–‰
    inputs:
      archive_months:
        description: "ì•„ì¹´ì´ë¹™í•  ê°œì›” ìˆ˜"
        required: false
        default: "6"
      cleanup_months:
        description: "ì‚­ì œí•  ê°œì›” ìˆ˜"
        required: false
        default: "6"

jobs:
  maintenance:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install supabase

      - name: Check capacity
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python scripts/check_db_capacity.py

      - name: Archive old posts
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python scripts/archive_old_posts.py

      - name: Upload archives
        uses: actions/upload-artifact@v3
        with:
          name: database-archives
          path: archives/*.csv
          retention-days: 90

      - name: Cleanup old posts
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python scripts/cleanup_old_posts.py

      - name: Final capacity check
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python scripts/check_db_capacity.py
```

## ì‹¤í–‰ ê³„íš

### ì´ˆê¸° ì„¤ì • (1íšŒ)

1. **SQL í•¨ìˆ˜ ìƒì„±**

   ```bash
   # Supabase SQL Editorì—ì„œ ì‹¤í–‰
   # - delete_old_posts_batch()
   # - check_database_size()
   ```

2. **ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±**

   ```bash
   mkdir -p scripts archives
   ```

3. **Python ìŠ¤í¬ë¦½íŠ¸ ìƒì„±**
   - `scripts/archive_old_posts.py`
   - `scripts/cleanup_old_posts.py`
   - `scripts/check_db_capacity.py`
   - `scripts/restore_archive.py`

4. **GitHub Actions ì›Œí¬í”Œë¡œìš° ì„¤ì •**
   - `.github/workflows/db_capacity_check.yml`
   - `.github/workflows/db_maintenance.yml`

5. **ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬**
   ```bash
   chmod +x scripts/*.py
   ```

### ì •ê¸° ì‹¤í–‰ (ìë™)

- **ë§¤ì£¼**: ìš©ëŸ‰ ì²´í¬ (ì¼ìš”ì¼ ìì •)
- **ë§¤ì›”**: ì•„ì¹´ì´ë¹™ + ì •ë¦¬ (1ì¼ ì˜¤ì „ 2ì‹œ)

### ìˆ˜ë™ ì‹¤í–‰ (í•„ìš”ì‹œ)

```bash
# 1. ìš©ëŸ‰ í™•ì¸
python scripts/check_db_capacity.py

# 2. ì•„ì¹´ì´ë¹™
python scripts/archive_old_posts.py

# 3. ì •ë¦¬
python scripts/cleanup_old_posts.py

# 4. ë³µì› (í•„ìš”ì‹œ)
python scripts/restore_archive.py archives/posts_archive_20240124.csv
```

## ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

### ê°„ë‹¨í•œ í†µê³„ ì¿¼ë¦¬

```sql
-- ì „ì²´ í˜„í™©
SELECT
  COUNT(*) as total_posts,
  COUNT(*) FILTER (WHERE created_at >= NOW() - INTERVAL '1 month') as last_month,
  COUNT(*) FILTER (WHERE created_at >= NOW() - INTERVAL '1 week') as last_week,
  pg_size_pretty(pg_total_relation_size('posts')) as table_size
FROM posts;

-- ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
SELECT
  category,
  COUNT(*) as count,
  pg_size_pretty(SUM(octet_length(title) + octet_length(COALESCE(summary, '')))) as size
FROM posts
GROUP BY category
ORDER BY count DESC;

-- ì˜¤ë˜ëœ ë°ì´í„° í™•ì¸
SELECT
  DATE_TRUNC('month', created_at) as month,
  COUNT(*) as posts,
  MIN(created_at) as oldest,
  MAX(created_at) as newest
FROM posts
WHERE created_at < NOW() - INTERVAL '6 months'
GROUP BY month
ORDER BY month;
```

## ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì›”ê°„ ìœ ì§€ë³´ìˆ˜

- [ ] ë°ì´í„°ë² ì´ìŠ¤ ìš©ëŸ‰ í™•ì¸
- [ ] 6ê°œì›” ì´ìƒ ëœ ë°ì´í„° ì•„ì¹´ì´ë¹™
- [ ] ì•„ì¹´ì´ë¹™ëœ ë°ì´í„° ì‚­ì œ
- [ ] ìµœì¢… ìš©ëŸ‰ í™•ì¸
- [ ] ì•„ì¹´ì´ë¸Œ íŒŒì¼ ë°±ì—… (ì™¸ë¶€ ì €ì¥ì†Œ)

### ë¶„ê¸°ë³„ ê²€í† 

- [ ] ë³´ê´€ ì •ì±… ì¬ê²€í† 
- [ ] í¬ë¡¤ë§ ë¹ˆë„ í™•ì¸
- [ ] ìš©ëŸ‰ ì¶”ì„¸ ë¶„ì„
- [ ] í•„ìš”ì‹œ ì •ì±… ì¡°ì •

## ë¬¸ì œ í•´ê²°

### ìš©ëŸ‰ì´ ê¸‰ê²©íˆ ì¦ê°€í•˜ëŠ” ê²½ìš°

1. í¬ë¡¤ëŸ¬ ì¤‘ë³µ ì²´í¬ í™•ì¸
2. summary í•„ë“œ ê¸¸ì´ í™•ì¸
3. ë¹„ì •ìƒì ì¸ ë°ì´í„° í™•ì¸

### ì•„ì¹´ì´ë¹™ ì‹¤íŒ¨

1. ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
2. ê¶Œí•œ í™•ì¸
3. Supabase ì—°ê²° í™•ì¸

### ì‚­ì œê°€ ëŠë¦° ê²½ìš°

1. ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸° (1000 â†’ 500)
2. ëŒ€ê¸° ì‹œê°„ ëŠ˜ë¦¬ê¸° (1ì´ˆ â†’ 2ì´ˆ)
3. ì¸ë±ìŠ¤ í™•ì¸

## ì°¸ê³  ìë£Œ

- [Supabase Database Documentation](https://supabase.com/docs/guides/database)
- [PostgreSQL Maintenance](https://www.postgresql.org/docs/current/maintenance.html)
- [ë°ì´í„°ë² ì´ìŠ¤ ê°€ì´ë“œ](./database.md)
